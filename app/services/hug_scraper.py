from dotenv import load_dotenv
import os
import re
from datetime import datetime
from playwright.sync_api import sync_playwright, expect
from app.supabase import get_supabase

# ==========================================
# ğŸ”¹ Load environment variables
# ==========================================
load_dotenv()
USERNAME = os.getenv("HUG_USERNAME")
PASSWORD = os.getenv("HUG_PASSWORD")


# ==========================================
# ğŸ”¹ Login Function
# ==========================================
def login(page):
    """Logs in to the HUG website using the provided page."""
    page.goto("https://www.hug-gioire.link/hug/wm/", wait_until="networkidle")
    page.get_by_role("textbox", name="ãƒ­ã‚°ã‚¤ãƒ³ID").fill(USERNAME)
    page.get_by_role("textbox", name="ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰").fill(PASSWORD)
    page.get_by_role("button", name="ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹").click()

    # Close the announcement popup if shown
    try:
        expect(page.locator("iframe").content_frame.get_by_role("heading", name="HUGã‹ã‚‰ã®ãŠçŸ¥ã‚‰ã›")).to_be_visible(timeout=5000)
        page.get_by_role("button", name="ï— é–‰ã˜ã‚‹").click()
    except Exception:
        pass

    expect(page.get_by_role("link", name="ïˆ‡ ä»Šæ—¥ã®é€è¿")).to_be_visible(timeout=10000)
    print("âœ… Successfully logged in!")


# ==========================================
# ğŸ”¹ Scraping Function
# ==========================================
def scrape_table(page):
    """Scrape rows from ä»Šæ—¥ã®é€è¿ page."""
    login(page)
    print("ğŸ” Starting full table scraping test...")

    # Go to ä»Šæ—¥ã®é€è¿
    page.get_by_role("link", name="ïˆ‡ ä»Šæ—¥ã®é€è¿").click()
    expect(page).to_have_url(re.compile(r"pickup\.php"))
    expect(page.locator("h1")).to_contain_text("ã®é€è¿ç®¡ç†")

    # Enable all facilities
    page.get_by_role("link", name="ï†ã™ã¹ã¦ãƒã‚§ãƒƒã‚¯").click()
    page.get_by_role("button", name="è¡¨ç¤ºå¤‰æ›´").click()

    expect(page.locator("div.pickTableWrap")).to_be_visible(timeout=15000)
    expect(page.locator("div.sendTableWrap")).to_be_visible(timeout=15000)

    def wait_section_ready(wrapper_css: str, timeout_ms: int = 15000):
        wrapper = page.locator(wrapper_css)
        try:
            wrapper.locator("table").first.wait_for(state="attached", timeout=timeout_ms)
        except Exception:
            page.wait_for_timeout(1000)

    wait_section_ready("div.pickTableWrap")
    wait_section_ready("div.sendTableWrap")

    all_rows = []

    def scrape_section(wrapper_class, pickup_flag):
        wrapper = page.locator(f"div.{wrapper_class}")
        if wrapper.locator("table").count() == 0:
            return

        rows = wrapper.locator("table tbody tr").all()
        for row in rows:
            if row.locator("div.nameBox").count() == 0:
                continue

            # --- ãŠè¿ãˆå¸Œæœ›æ™‚é–“ ---
            time_cell = row.locator("td.greet_time_scheduled")
            target_time = None
            if time_cell.count() > 0:
                text = time_cell.inner_text().strip()
                if text and text != "9999":
                    target_time = text

            # --- å…ç«¥å ---
            raw_name = row.locator("div.nameBox").inner_text().replace("\n", " ").strip()

            # Normalize multiple spaces â†’ one full-width space
            user_name = re.sub(r"\s+", "ã€€", raw_name)

            # --- æ–½è¨­å ---
            depot_cell = row.locator("td").nth(2)
            depot_name = depot_cell.inner_text().strip() if depot_cell.count() > 0 else None

            # --- å ´æ‰€ (handle æ¬ å¸­ + é€è¿ãªã—) ---
            if row.locator("td.absence").count() > 0:
                place = "æ¬ å¸­"
            else:
                place_cell = row.locator("td.place")
                if place_cell.count() > 0:
                    place_text = place_cell.inner_text().strip()
                    place = place_text if place_text else "é€è¿ãªã—"
                else:
                    place = "é€è¿ãªã—"

            all_rows.append({
                "target_time": target_time,
                "user_name": user_name,
                "depot_name": depot_name,
                "place": place,
                "pickup_flag": pickup_flag,
            })

    scrape_section("pickTableWrap", "è¿ãˆ")
    scrape_section("sendTableWrap", "é€ã‚Š")

    print(f"âœ… Finished scraping. Found {len(all_rows)} rows.\n")
    return all_rows


# ==========================================
# ğŸ”¹ Clear Previous Data
# ==========================================
def clear_previous_data():
    """Delete all existing data in stg.hug_raw_requests before inserting new data."""
    supabase = get_supabase()
    print("ğŸ§¹ Clearing previous staging data...")
    try:
        response = supabase.schema("stg").from_("hug_raw_requests").delete().neq("id", 0).execute()
        print(f"âœ… Cleared previous records: {len(response.data or [])}\n")
    except Exception as e:
        print("âš ï¸ Failed to clear previous data:", e)


# ==========================================
# ğŸ”¹ Supabase Insert Logic
# ==========================================
def insert_scraped_data_to_supabase(scraped_rows):
    """Insert scraped pickup/drop-off data into stg.hug_raw_requests."""
    supabase = get_supabase()
    print("ğŸš€ Inserting scraped rows into Supabase...")

    formatted_rows = []
    for row in scraped_rows:
        try:
            time_str = row.get("target_time")
            user_name = row.get("user_name")
            depot_name = row.get("depot_name")
            place = row.get("place")
            pickup_text = row.get("pickup_flag")
            pickup_flag = pickup_text.strip() == "è¿ãˆ"

            target_dt = None
            if time_str:
                try:
                    today = datetime.now().strftime("%Y-%m-%d")
                    dt_str = time_str.replace("ï¼š", ":")
                    target_dt = datetime.strptime(f"{today} {dt_str}", "%Y-%m-%d %H:%M")
                except Exception:
                    target_dt = None

            formatted_rows.append({
                "pickup_flag": pickup_flag,
                "user_name": user_name.strip(),
                "depot_name": depot_name.strip() if depot_name else None,
                "place": place.strip() if place else None,
                "target_time": target_dt.isoformat() if target_dt else None,
                "payload": {"raw_row": row}
            })
        except Exception:
            continue

    if not formatted_rows:
        print("âŒ No valid rows to insert.\n")
        return

    try:
        supabase.schema("stg").from_("hug_raw_requests").insert(formatted_rows).execute()
        print(f"âœ… Insert complete: {len(formatted_rows)} rows added.\n")
    except Exception as e:
        print("âŒ Insert failed:", e)


# ==========================================
# ğŸ”¹ Main Runner
# ==========================================
def main():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False, slow_mo=150)
        page = browser.new_page()
        all_rows = scrape_table(page)
        browser.close()

    clear_previous_data()
    insert_scraped_data_to_supabase(all_rows)


if __name__ == "__main__":
    main()
